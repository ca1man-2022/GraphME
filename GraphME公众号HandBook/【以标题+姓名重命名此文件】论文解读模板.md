>写在前面：
>
>1、一定要：新建一个文件夹`image`，与该markdown文件同位置，用以存放以下将要涉及的图片，在命名中体现图片在本文中出现的顺序（如img1_motivation/img2_ablation/...）。成文之后连同图片一起打包发送。
>
>2、一定要：使用**中文**标点符号，注意检查：中文和英文之间不加空格。编辑公式使用`$...$`或`$$...$$`符号，前者嵌在行内，后者会换行显示。
>
>3、注意：插入图片前先换行，即图片和前述文字内容要留空行。原则是：空行可以多几行但不能没有。
>
>3、注意：markdown语言和latex语言不完全互通，不要直接粘贴论文中的公式代码。
>
>4、注意：本文主要是为了展示常用MD语法，其中的内容与写作框架仅供参考、实际按个人解读风格进行修改。
>
>5、推荐大家下载一个markdown编辑器进行撰写，而非盲写；不愿下载软件可以使用在线网站：https://www.67tool.com/work/markdown，但，推荐前者。
# AAAI25||ML-GOOD ：面向多标签图结构数据的分布外检测**【推文标题】**

题目：ML-GOOD: Towards Multi-Label Graph Out-Of-Distribution Detection

作者：T. Cai, M. Li, P. Lio**【三字、两字、外文名字示例，仅此处符号是英文，且空1格】**

单位：浙江师范大学，浙江光电子研究院，xxxxx

摘要：图结构数据的分布外（Out-Of-Distribution, OOD）检测对于在开放世界场景中安全部署图神经网络至关重要。然而，现有方法忽略了现实世界应用中多标签分类的普遍场景。在这项工作中，我们研究了多标签节点分类任务中尚未被探索的OOD检测问题。我们提出了ML-GOOD，这是一种简单而充分的方法，它利用能量函数来衡量每个标签的OOD分数。我们进一步开发了一种融合多个标签能量的策略，允许综合利用标签信息来应对多标签场景中遇到的主要挑战。我们在七个不同的真实世界多标签图数据集上进行了广泛的实验，其中包括跨领域场景。结果表明，与之前的方法相比，ML-GOOD在域内场景中AUROC提高了5.26%，跨域场景中的AUROC提高了6.54%。这些实验不仅肯定了我们的方法的稳健性，还为这一新兴研究领域的进一步探索指明了新的途径。

代码：https://github.com/ca1man-2022/ML-GOOD


## 1.背景与动机
随着图神经网络（GNNs）在欺诈检测、医学诊断等领域的广泛应用，如何在开放环境中精准识别分布外（OOD）样本已成为关键问题。
然而，现有OOD检测方法几乎都聚焦于单标签任务，忽视了现实中多标签任务的复杂性。例如：
- 在蛋白质-蛋白质交互网络中，每个蛋白质往往与多个功能相关联。
- 在社交网络中，用户可能拥有多种兴趣标签。

但是，多标签场景下，简单依赖单一标签信息的OOD检测可能引入估计偏差。如何准确利用多标签信息、避免高信息量标签被忽略是当前未解的难题。
举例如图所示的蛋白质预测任务：在蛋白质预测等多标签节点分类任务中，应该考虑采用一种多标签方法，联合利用节点的所有标签信息进行OOD检测，
而不是被高信息量标签（dominant label）所蒙蔽。

![alt text](image-1.png)
图1：多标签节点分类中的OOD检测。

**我们的创新方法：ML-GOOO**
- 提出新视角：首次探索多标签图OOD检测问题，为该领域提供明确的问题定义，并为多标签数据集的分布定义了一个分区标准。
- 设计能量函数框架：提出了一种基于标签能量的OOD检测方法（ML-GOOD），量化节点与标签的关联强度。并针对多标签任务的特点，提出统一能量与典型能量融合的计算策略，提升检测效果。
- ML-GOOD的理论基础：我们为ML-GOOD在图OOD检测中的有效性提供了明确的理论依据。通过数学推理，我们证明了我们的方法的实用性和可靠性。
- 我们在7个真实多标签图数据集（包括单图、多图和跨域场景）上进行了全面验证，ML-GOOD在性能指标（如AUPR、FPR95等）上超越现有基准方法，同时保持优秀的分布内分类性能。

## 2.符号与预备知识
### 2.1.基于能量的模型 (Energy-Based Models, EBMs)

基于能量的模型 (EBMs)是一种统计框架，通过能量函数$E(\mathbf{x})$对变量的配置进行建模。其学习目标是使正确的配置对应较低的能量，而错误的配置对应较高的能量。

在判别模型中（例如神经分类器 $f(\mathbf{x})$），输入会被映射为logits，随后通过 softmax 函数转化为概率分布：  
$$
p(y | \mathbf{x}) = \frac{e^{f_y(\mathbf{x}) / \tau}}{\sum_i^k e^{f_i(\mathbf{x}) / \tau}}
$$
其中，$f_y(\mathbf{x})$ 表示与第$y$类标签对应的logit值，$\tau$为温度参数。这一公式适用于单标签分类任务。

在EBMs中，利用logits定义概率密度$p(\mathbf{x})$，并通过玻尔兹曼分布（Boltzmann Distribution）表示：  
$$
p(y | \mathbf{x}) = \frac{e^{-E(\mathbf{x}, y) / \tau}}{\int_{{y}'} e^{-E(\mathbf{x}, {y}') / \tau}} = \frac{e^{-E(\mathbf{x}, y) / \tau}}{e^{-E(\mathbf{x}) / \tau}}
$$
其中，能量值的定义为 $E(\mathbf{x}, y) = -f_y(\mathbf{x})$。  
根据softmax分母项可以进一步导出自由能函数（Free Energy Function）$E(\mathbf{x}; f)$：  
$$
E(\mathbf{x}; f) = -\tau \cdot \log \sum^k_i e^{f_i(\mathbf{x}) / \tau}
$$

### 2.2.符号表
![alt text](image.png)

### 2.3.定义 1（多标签图OOD检测）

在涉及真实世界图数据集的场景中，我们通常会遇到两种主要类型：单图数据集和多图数据集。
OOD检测的主要目标是：**对已知分布内（IND）数据的类别进行精准预测，同时对识别为OOD的数据拒绝进行预测**。
因此，多标签图OOD检测的目标可以简洁地表述如下：  
$$
\hat{y}_{ij} = 
\begin{cases} 
f(\mathbf{x}_i, \mathcal{G})_{[j]}, & \text{若 } \mathbf{x}_i \sim D_{in}, \\  
\text{reject}, & \text{若 } \mathbf{x}_i \sim D_{out}.
\end{cases}
$$

其中，$\mathbf{x}_i$表示节点$v_i$的特征，分类器$f(\cdot)$预测节点$v_i$的第$j$个标签，$j=1, 2, \cdots, k$。为简化表达，下文统一考虑多图数据的情况。

在这里，我们以单图数据集为例进行介绍。在本文中，我们提出的问题定义是全面的，涵盖了图OOD检测的所有场景，包括从单标签到多标签，从单图到多图的情况，详见论文。

## 3.ML-GOOD方法论
我们提出了 ML-GOOD (**M**ulti-**L**abel **G**raph **O**ut-**O**f-**D**istribution Detection)，用于在多标签图分类任务中检测OOD样本。ML-GOOD通过GNNs捕获图的内在关系，结合基于标签的能量学习生成每个标签的能量分数，并通过统一与典型能量聚合方法计算最终的OOD分数。此方法还辅以严格的数学分析和理论支持。

![alt text](image-2.png)
图2：ML-GOOD的总体框架。ML-GOOD方法整体框架分为两步：图的标签特定能量学习（步骤I）和基于标签特定能量函数的OOD检测（步骤II）。步骤I：图的标签特定能量学习。首先，我们利用GCN捕获图数据的相关性，通过标签特定能量学习获取每个节点各标签的初始能量分数。步骤II：基于标签特定能量函数的OOD检测。首先计算统一能量和典型能量分数，并进行分数聚合以得出节点的OOD分数（即$E_{ML}$）。最后，应用阈值$\alpha$判断节点是否属于OOD样本。

### 3.1.基于标签的能量学习

#### 3.1.1 特征提取

在图结构数据中，节点代表实体，边代表这些实体之间的关系。不同于图像数据的网格结构，图数据的复杂性来源于节点的多样性和关系的丰富性。在多标签图分类中，每个节点可能对应多个标签，这反映了节点的多重属性或角色。为此，我们使用图卷积网络（GCNs）捕获节点之间的依赖关系。节点 $v_i$ 在第 $l$ 层的特征表示为： 
$$
\mathbf{h}^{(l)}_{v_i} = \phi{(\mathbf{h}_{v_i}^{(l-1)}, \text{AGG}(\{\mathbf{h}_{u}^{(l-1)}\}_{{u}\in \mathcal{N}(v_i)}))}
$$
其中，$\text{AGG}(\cdot)$为聚合函数，$\phi(\cdot)$为非线性激活函数，$\mathcal{N}(v_i)$为节点$v_i$的1-hop邻居集合。经过 $L$ 层卷积后，GCN输出的节点表示 $\mathbf{h}^{(L)}_{v_i}$ 作为后续能量计算的基础。

#### 3.1.2 标签特定能量学习

对于每个节点$v_i$的第$j$个标签 $y_{ij}$，我们定义一个标签特定能量函数$E(\mathbf{x}_i, \mathcal{G}; j)$：  
$$
E(\mathbf{x}_i, \mathcal{G}; j) = -\log(1 + e^{h_{\mathbf{x}_i, \mathcal{G}}^j})
$$
其中$h_{\mathbf{x}_i, \mathcal{G}}^j$是节点$v_i$第$j$个标签的logit值。此能量函数反映了能量值与标签关联可能性的反比关系。

### 3.2.基于能量的OOD检测

为了计算每个节点的最终OOD分数，我们综合了统一能量与典型能量：  
$$
E_{ML}(\mathbf{x}_i,\mathcal{G}) = -\frac{1}{k} \sum_{j=1}^k \log(1+e^{h_{\mathbf{x}_i, \mathcal{G}}^j}) - \log(1+e^{\min\limits_j h_{\mathbf{x}_i, \mathcal{G}}})
$$
统一能量捕获所有标签的平均信息，而典型能量进一步考虑每个节点中能量最大的标签，确保高能量标签不会被忽略。

### 3.3.优化目标

为了在多标签分类任务中优化模型性能，我们采用二元交叉熵损失 $\mathcal{L}_{bce}$ 和能量间隔损失 $\mathcal{L}_{gap}$：  
$$
\mathcal{L}_{gap} = \mathbb{E}_{(\mathbf{x}_{in}, \mathbf{y}) \sim \mathcal{D}_{in}^{train}} [ \text{ReLU}(E_{ML}^{in} - m_{in})^2 ] + \mathbb{E}_{(\mathbf{x}_{out}, \mathbf{y}) \sim \mathcal{D}_{out}^{train}} [ \text{ReLU}(m_{out} - E_{ML}^{out})^2 ]
$$
最终优化目标为：  
$$
\mathcal{L} = \mathcal{L}_{bce} + \lambda \cdot \mathcal{L}_{gap}
$$
其中 $\lambda$ 是平衡两个损失项的正则化系数。

## 4.部分实验结果
表1列出了我们的方法在OGB-Proteins和PPI数据集上的性能评估。利用多标签条件下图数据的结构特征，我们的方法在一系列关键指标上都表现出优于其他竞争方法的性能。尤其值得注意的是，我们的方法能够保持有竞争力的OOD检测性能，同时在OGB-Proteins数据集上保持出色的分布内分类准确性。

![alt text](image-3.png)
表1：在OGB-Proteins和PPI数据集上的性能评估。

此外，我们注意到，关于图OOD检测的现有文献尚未就所使用数据集的规格达成共识：是使用单个数据集还是多个数据集。考虑到对比场景的完整性，我们首先组合了相似域表现的两组图数据的多标签数据集，随后在该设置下跨数据集的实验。表2列出了跨数据集情况下的OOD检测结果。结果表明，我们的方法在跨域OOD检测的性能仍然保持优势。此外，针对图结构数据设计的定制方法证明比那些假设输入独立和统一的方法更有效。总之，对实验结果的分析强调了我们的方法在区分IND和OOD样本方面的稳健性和有效性。

![alt text](image-4.png)
表2：跨域数据集上的性能评估。

为了直观地说明我们的方法所产生的影响，我们展示了IND和OOD输入的能量得分分布，如图3所示。我们的研究结果表明，针对特定标签的计算方法能有效区分IND和OOD数据之间的能量差异，从而表明ML-GOOD在检测OOD节点方面具有直观的能力。此外，这一观察结果证实了我们最初的假设，即存在同时与多个标签相关联的节点，并强调了考虑每个标签对应的能量分数的重要性。这种考虑能够更细致地描述关系中的潜在复杂性，而只关注最大能量得分可能会忽略这一方面。因此，我们的结果肯定了所提出的特定标签能量分数计算和正则化方法的有效性。

![alt text](image-5.png)
图3：在PCG数据集上的能量分布情况。“LS”表示标签特定能量学习策略。

## 5.结论
在本文中，我们探讨了多标签图分布外（GOOD）检测这一新兴问题。在理论分析的支持下，我们提出了一种特定于标签的能量函数，能够有效地整合多标签信息，计算GOOD能量得分。通过广泛的实验和讨论，我们验证了我们方法（即ML-GOOD）的有效性。我们希望能够引起更多研究者对多标签图分类中的OOD检测问题的兴趣。

作者主页：https://ca1man-2022.github.io/

附录内容可在代码链接中找到。

---

@author: ca1man

2024.12.26 edited

2025.01.03 modified

